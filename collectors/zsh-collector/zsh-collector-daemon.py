# /usr/bin/python3"""Retrieve history entries from a zsh histdb database.TODO: - Verify config and filepaths are ok"""from configparser import ConfigParser, ExtendedInterpolationimport timeimport jsonimport sqlite3import sysimport collectord_messagequeue# SQL query reading up to 10 items, use the named parameter :min_id# to only get items with id strictly greater than min_idquery = """SELECT  max_start as timestamp,  dir as directory,  argv as commandFROM  (SELECT    replace(places.dir, '/home/jfa', '~') as dir,    replace(commands.argv, '', '') as argv,    max(start_time) as max_start  FROM    commands    JOIN history ON history.command_id = commands.id    JOIN places ON history.place_id = places.id    WHERE 1 AND places.host='jfas-dell'  GROUP BY history.command_id, history.place_id  ORDER BY max_start DESC  LIMIT 10)WHERE 1 and max_start > :min_timestampORDER BY max_start ASC"""def main(*, config_path) -> None:    config = get_config(config_path)    poll_delay = int(config['ZshCollector']['pollingDelayInSeconds'])    # Connect to socket    connect_to_messagequeue(config['CollectorDaemon']['host'],                            config['CollectorDaemon']['port'])    # Initialize the collection dictionnary    collection_object = {'source': "zsh_collector_daemon.py",                         'version': '0.0.1'}    # Read the latest id from cache    latest_timestamp = read_last_timestamp(config['ZshCollector']['cacheFp'])    with sqlite3.connect(config['ZshCollector']['databaseFp']) as conn:        conn.row_factory = sqlite3.Row        # Polling loop        while True:            cursor = conn.execute(query, {"min_timestamp": latest_timestamp})            query_max_timestamp = -1            for row in cursor:                print(f"NEW ROW:\n    {dict(row)}")                collection_object.update(dict(row))                send_to_message_queue(collection_object)                if row['timestamp'] > query_max_timestamp:                    query_max_timestamp = row['timestamp']            if query_max_timestamp > -1:                latest_timestamp = query_max_timestamp                # TODO Only do this before exit                cache_last_timestamp(config['ZshCollector']['cacheFp'], latest_timestamp)            else:                print("No new rows")            time.sleep(poll_delay)def send_to_message_queue(data: dict) -> None:    """    Encode into json format and send the data to the given socket    """    jsondump = json.dumps(data)    print(f"Sending to message queue: {jsondump}")    collectord_messagequeue.send_message(socket, jsondump)    print("done")def cache_last_timestamp(filepath, timestamp: int) -> None:    """    Format has to be in number    of seconds from unix epoch.    """    with open(filepath, 'w') as cache:        cache.write(str(timestamp))def read_last_timestamp(filepath) -> int:    """    Read the last timestamp from the cache, or create the cache file and return 0.    """    timestamp = 0    try:        with open(filepath, 'r') as cache:            timestamp = int(cache.readline())    except FileNotFoundError as e:        print(f"Zsh_collector: Did not find cache file at {filepath}, creating it.")        cache_last_timestamp(filepath, 0)    return timestampdef connect_to_messagequeue(host, port):    global socket    socket = collectord_messagequeue.start_client(host, port)    if not socket:        print(f"Zsh collector: Connection to {host}:{port} failed...")        exit(1)    print("socket good to go!")def get_config(filepath) -> ConfigParser:    """    Parse the .ini file provided for configuration options    """    print("Starting Zsh collector daemon")    config = ConfigParser(interpolation=ExtendedInterpolation())    config.read(filepath)    return configif __name__ == '__main__':    main(config_path='zsh-collector-config.ini')